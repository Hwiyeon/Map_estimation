{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version [1.3.1]\n",
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  ## just for ignore DeprcationWarning message\n",
    "print(\"Current version [%s]\" %(tf.__version__))\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAGS READY\n"
     ]
    }
   ],
   "source": [
    "# Dataset Configurations\n",
    "tf.app.flags.DEFINE_integer('img_size', 64, \"\"\"Image size of MAP dataset\"\"\")\n",
    "tf.app.flags.DEFINE_string('train_dir', './../../Rent3D-modified/crop_imgs/train', \"\"\"Dir contains train data\"\"\")\n",
    "tf.app.flags.DEFINE_string('test_dir', './../../Rent3D-modified/crop_imgs/test', \"\"\"Dir contains test data\"\"\")\n",
    "\n",
    "# Network Configurations\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"\"\"Number of images to process in a batch\"\"\")\n",
    "# tf.app.flags.DEFINE_float('l1_ratio', 0.5, \"\"\"Ratio of level1\"\"\")\n",
    "# tf.app.flags.DEFINE_float('l2_ratio', 0.5, \"\"\"Ratio of level2\"\"\")\n",
    "\n",
    "# Optimization Configurations\n",
    "tf.app.flags.DEFINE_float('lr', 0.001, \"\"\"Learning rate\"\"\")\n",
    "\n",
    "# Training Configurations\n",
    "tf.app.flags.DEFINE_integer('training_epochs', 200, \"\"\"Number of epochs to run\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step', 1, \"\"\"Number of iterations to display training output\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_step', 5, \"\"\"Number of interations to save checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_max', 5, \"\"\"Number of checkpoints to remain\"\"\")\n",
    "\n",
    "\n",
    "# Save Configurations\n",
    "tf.app.flags.DEFINE_string('nets', './nets', \"\"\"Directory where to write the checkpoints\"\"\")\n",
    "tf.app.flags.DEFINE_string('outputs', './outputs', \"\"\"Directory where to save the output images\"\"\")\n",
    "tf.app.flags.DEFINE_string('tboard', './tensorboard', \"\"\"Directory where to save the tensorboard logs\"\"\")\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "print(\"FLAGS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "train_dir = FLAGS.train_dir\n",
    "train_img = os.listdir(train_dir)\n",
    "train_img.sort()\n",
    "\n",
    "test_dir = FLAGS.test_dir\n",
    "test_img = os.listdir(test_dir)\n",
    "test_img.sort()\n",
    "\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating observation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_mask():\n",
    "    mask = np.zeros([FLAGS.img_size, FLAGS.img_size])\n",
    "    # threshold of the size of masks\n",
    "    uthd = FLAGS.img_size    \n",
    "    lthd = 0     \n",
    "    # mask size should be beween 48x48, 16x16\n",
    "    while(uthd>48 or lthd<16):\n",
    "        ver1 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)   # vertex1\n",
    "        ver2 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)    # vertex2\n",
    "        uthd = np.maximum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # upperbound\n",
    "        lthd = np.minimum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # lowerbound\n",
    "    xmin = np.minimum(ver1[0], ver2[0])    # left x value\n",
    "    xmax = np.maximum(ver1[0], ver2[0])    # right x value\n",
    "    ymin = np.minimum(ver1[1], ver2[1])    # top y value\n",
    "    ymax = np.maximum(ver1[1], ver2[1])    # bottom y value\n",
    "    observe = np.ones([xmax-xmin+1, ymax-ymin+1])    # observation area\n",
    "    mask[xmin:xmax+1, ymin:ymax+1] = observe    # observation with location\n",
    "#     mask = np.reshape(mask, [-1])\n",
    "    return mask\n",
    "\n",
    "def observe_batch(batch_num):\n",
    "    # make random noise batch\n",
    "    mask_batch = np.zeros([batch_num, FLAGS.img_size,FLAGS.img_size])\n",
    "    for i in range(batch_num):\n",
    "        mask_batch[i] = observe_mask()\n",
    "    return mask_batch\n",
    "\n",
    "def observe(full, obs):\n",
    "    return np.multiply(full, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "# Network Topology\n",
    "n_input = FLAGS.img_size*FLAGS.img_size\n",
    "n_enc1 = 512\n",
    "n_enc2 = 256\n",
    "n_enc3 = 128\n",
    "n_dec1 = 256\n",
    "n_dec2 = 512\n",
    "n_out = FLAGS.img_size*FLAGS.img_size\n",
    "\n",
    "# Inputs and Outputs\n",
    "x = tf.placeholder(\"float\", [None, FLAGS.img_size])\n",
    "y = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "# Nework Parameters\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'enc1' : tf.Variable(tf.random_normal([n_input, n_enc1], stddev=stddev)),\n",
    "    'enc2' : tf.Variable(tf.random_normal([n_enc1, n_enc2], stddev=stddev)),\n",
    "    'enc3' : tf.Variable(tf.random_normal([n_enc2, n_enc3], stddev=stddev)),\n",
    "    'dec1' : tf.Variable(tf.random_normal([n_enc3, n_dec1], stddev=stddev)),\n",
    "    'dec2' : tf.Variable(tf.random_normal([n_dec1, n_dec2], stddev=stddev)),\n",
    "    'out' : tf.Variable(tf.random_normal([n_dec2, n_out], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'enc1' : tf.Variable(tf.random_normal([n_enc1], stddev=stddev)),\n",
    "    'enc2' : tf.Variable(tf.random_normal([n_enc2], stddev=stddev)),\n",
    "    'enc3' : tf.Variable(tf.random_normal([n_enc3], stddev=stddev)),\n",
    "    'dec1' : tf.Variable(tf.random_normal([n_dec1], stddev=stddev)),\n",
    "    'dec2' : tf.Variable(tf.random_normal([n_dec2], stddev=stddev)),\n",
    "    'out' : tf.Variable(tf.random_normal([n_out], stddev=stddev))\n",
    "}\n",
    "\n",
    "print(\"Network Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Ready\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "def ae(_X, _weights, _biases):\n",
    "    _x_r = tf.reshape(_X, shape=[-1, FLAGS.img_size*FLAGS.img_size])\n",
    "    enc1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['enc1']),_biases['enc1']))\n",
    "    enc2 = tf.nn.sigmoid(tf.add(tf.matmul(enc1, _weights['enc2']),_biases['enc2']))\n",
    "    enc3 = tf.nn.sigmoid(tf.add(tf.matmul(enc2, _weights['enc3']),_biases['enc3']))\n",
    "    dec1 = tf.nn.sigmoid(tf.add(tf.matmul(enc3, _weights['dec1']),_biases['dec1']))\n",
    "    dec2 = tf.nn.sigmoid(tf.add(tf.matmul(dec1, _weights['dec2']),_biases['dec2']))\n",
    "    out = tf.nn.sigmoid(tf.add(tf.matmul(dec2, _weights['out']),_biases['out']))\n",
    "    _out = {\n",
    "        'enc1' : enc1,\n",
    "        'enc2' : enc2,\n",
    "        'enc3' : enc3,\n",
    "        'dec1' : dec1,\n",
    "        'dec2' : dec2,\n",
    "        'out' : out\n",
    "    }\n",
    "    return _out\n",
    "\n",
    "# Generation\n",
    "gen = ae(x, weights, biases)['out']    # [None, n_input]\n",
    "\n",
    "# Loss & Optimizer\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.l2_loss(gen-y))\n",
    "    train_loss = tf.summary.scalar(\"train_loss\", cost)\n",
    "    test_loss = tf.summary.scalar(\"test_loss\", cost)\n",
    "counter = 0\n",
    "\n",
    "optm = tf.train.AdamOptimizer(learning_rate=FLAGS.lr).minimize(cost)\n",
    "\n",
    "\n",
    "print(\"Graphs Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Ready\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "tensorboard_path = FLAGS.tboard\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)\n",
    "writer = tf.summary.FileWriter(tensorboard_path)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print(\"Initialize Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saver ready\n"
     ]
    }
   ],
   "source": [
    "outputdir = FLAGS.outputs\n",
    "if not os.path.exists(outputdir+'/train'):\n",
    "    os.makedirs(outputdir+'/train')\n",
    "\n",
    "if not os.path.exists(outputdir+'/test'):\n",
    "    os.makedirs(outputdir+'/test')\n",
    "    \n",
    "savedir = FLAGS.nets\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=FLAGS.save_max)\n",
    "print(\"Saver ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 64, 64) for Tensor u'Placeholder:0', which has shape '(?, 4096)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1f19e55cc91c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtrain_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1101\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 64, 64) for Tensor u'Placeholder:0', which has shape '(?, 4096)'"
     ]
    }
   ],
   "source": [
    "#%%debug\n",
    "# Parameters\n",
    "training_epochs = FLAGS.training_epochs\n",
    "batch_size = FLAGS.batch_size\n",
    "display_step = FLAGS.display_step\n",
    "# Plot\n",
    "n_plot = 5    # plot 5 images\n",
    "train_disp_idx = np.copy(np.random.choice(train_img, size=n_plot, replace=False))    # fixed during train time\n",
    "test_disp_idx = np.copy(np.random.choice(test_img, size=n_plot, replace=False))\n",
    "with tf.device('/cpu:0'):\n",
    "    train_disp_img = []\n",
    "    test_disp_img = []\n",
    "    for img in range(n_plot):\n",
    "        train_disp_img.append(misc.imread(train_dir+'/'+train_disp_idx[img]))\n",
    "        test_disp_img.append(misc.imread(test_dir+'/'+test_disp_idx[img]))\n",
    "    train_disp_mask = observe_batch(n_plot)\n",
    "    train_disp_obs = observe(train_disp_img, train_disp_mask)\n",
    "    test_disp_mask = observe_batch(n_plot)\n",
    "    test_disp_obs = observe(train_disp_img, train_disp_mask)\n",
    "\n",
    "# Initialize\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "# Optimize\n",
    "for epoch in range(training_epochs):\n",
    "    total_cost = 0.\n",
    "    n_total_batch = int(np.size(train_img)/batch_size)\n",
    "    rand_train_idx = np.random.choice(train_img, size=batch_size, replace=False)    # For display losses\n",
    "    rand_test_idx = np.random.choice(test_img, size=batch_size, replace=False)    # For display losses\n",
    "    \n",
    "    np.random.seed(epoch)\n",
    "    np.random.shuffle(train_img)\n",
    "        \n",
    "    # Iteration\n",
    "    for batch in range(n_total_batch):\n",
    "        with tf.device('/cpu:0'):\n",
    "            batch_img = []\n",
    "            for img in range(batch_size):\n",
    "                batch_img.append(misc.imread(train_dir+'/'+train_img[batch*batch_size + img]))\n",
    "            train_mask = observe_batch(batch_size)\n",
    "            train_obs = observe(batch_img, train_mask)\n",
    "            feeds = {x: train_obs, y:batch_img}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_batch_img = []\n",
    "        test_batch_img = []\n",
    "        for img in range(batch_size):\n",
    "            train_batch_img.append(misc.imread(train_dir+'/'+rand_train_idx[img]))\n",
    "            test_batch_img.append(misc.imread(test_dir+'/'+rand_test_idx[img]))\n",
    "        train_batch_mask = observe_batch(batch_size)\n",
    "        train_batch_obs = observe(train_batch_img, train_batch_mask)\n",
    "        train_feeds = {x: train_batch_obs, y:train_batch_img}\n",
    "        test_batch_mask = observe_batch(batch_size)\n",
    "        test_batch_obs = observe(test_batch_img, test_batch_mask)\n",
    "        test_feeds = {x: test_batch_obs, y:test_batch_img}\n",
    "    train_loss, tb_train_loss = sess.run([loss,_train_loss], feed_dict=train_feeds)\n",
    "    test_loss, tb_test_loss = sess.run([loss,_test_loss], feed_dict=test_feeds)\n",
    "    \n",
    "    writer.add_summary(tb_train_loss, epoch)\n",
    "    writer.add_summary(tb_test_loss, epoch)\n",
    "    print(\"Epoch : %03d/%03d  Train_loss : %.7f  Test_loss : %.7f\" \n",
    "          % (epoch+1, training_epochs, train_loss, test_loss))   \n",
    "        \n",
    "    # Display\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        # generated images\n",
    "        train_gen_full = sess.run(gen, feed_dict={x:train_disp_img})  \n",
    "        test_gen_full = sess.run(gen, feed_dict={x:test_disp_img})\n",
    "        \n",
    "        # plotting results from training data\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=n_plot, figsize=(10,10))   # displaying 4*n_plot images\n",
    "        plt.setp(axes, xticks=np.arange(0,63,8), yticks=np.arange(0,63,8)) \n",
    "        for j in range(n_plot):\n",
    "            train_disp_full_map = np.reshape(train_disp_img[j], [64,64])    # 28x28\n",
    "            axes[0, j].imshow(train_disp_full_map, cmap='gray')   \n",
    "            axes[0, j].set(ylabel='gt_map')\n",
    "            axes[0, j].label_outer()\n",
    "            \n",
    "            train_obs = np.reshape(train_disp_obs[j], [64,64])    # 28x28\n",
    "            axes[1, j].imshow(train_obs, cmap='gray')   \n",
    "            axes[1, j].set(ylabel='observe')\n",
    "            axes[1, j].label_outer()\n",
    "            \n",
    "            train_disp_gen_full = np.reshape(train_gen_full[j], [64,64])    # 28x28\n",
    "            axes[2, j].imshow(train_disp_gen_full, cmap='gray')   \n",
    "            axes[2, j].set(ylabel='full_map')\n",
    "            axes[2, j].label_outer()\n",
    "                    \n",
    "        plt.savefig(outputdir+'/train/epoch %03d' %(epoch+1))    \n",
    "        plt.close(fig)\n",
    "        \n",
    "        # plotting results from testing data\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=n_plot, figsize=(10,10))   # displaying 4*n_plot images\n",
    "        plt.setp(axes, xticks=np.arange(0,63,8), yticks=np.arange(0,63,8)) \n",
    "        for j in range(n_plot):\n",
    "            test_disp_full_map = np.reshape(test_disp_img[j], [64,64])    # 28x28\n",
    "            axes[0, j].imshow(test_disp_full_map, cmap='gray')   \n",
    "            axes[0, j].set(ylabel='gt_map')\n",
    "            axes[0, j].label_outer()\n",
    "            \n",
    "            test_obs = np.reshape(test_disp_obs[j], [64,64])    # 28x28\n",
    "            axes[1, j].imshow(test_obs, cmap='gray')   \n",
    "            axes[1, j].set(ylabel='observe')\n",
    "            axes[1, j].label_outer()\n",
    "            \n",
    "            test_disp_gen_full = np.reshape(test_gen_full[j], [64,64])    # 28x28\n",
    "            axes[2, j].imshow(test_disp_gen_full, cmap='gray')   \n",
    "            axes[2, j].set(ylabel='full_map')\n",
    "            axes[2, j].label_outer()        \n",
    "                                \n",
    "        plt.savefig(outputdir+'/test/epoch %03d' %(epoch+1))    \n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Save\n",
    "        if (epoch+1) % FLAGS.save_step ==0:\n",
    "            savename = savedir+\"/net-\"+str(epoch+1)+\".ckpt\"\n",
    "            saver.save(sess, savename)\n",
    "            print(\"[%s] SAVED\" % (savename))\n",
    "\n",
    "print(\"Optimization Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_restore = 1\n",
    "if do_restore == 1:\n",
    "    sess = tf.Session()\n",
    "    epoch = 500\n",
    "    savename = savedir+\"/net-\"+str(epoch)+\".ckpt\"\n",
    "    saver.restore(sess, savename)\n",
    "    print (\"NETWORK RESTORED\")\n",
    "else:\n",
    "    print (\"DO NOTHING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disp_idx = np.random.randint(mnist.test.num_examples, size=5)\n",
    "test_gt_pure = test_img[test_disp_idx]    # pure image\n",
    "test_gt_noise = noise_batch(n_plot)    # random noise\n",
    "test_gt_crpt = occl(test_gt_pure,test_gt_noise)   # corrupted image\n",
    "test_gt_feeds = {ph_crpt: test_gt_crpt}\n",
    "test_gen_pure, test_gen_noise, test_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                                        feed_dict=test_gt_feeds)\n",
    "\n",
    "# plotting results from testing data\n",
    "fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,10))   # displaying 4*n_plot images\n",
    "plt.setp(axes, xticks=np.arange(0,27,7), yticks=np.arange(0,27,7)) \n",
    "for t in range(5):\n",
    "    test_disp_gt_crpt = np.reshape(test_gt_crpt[t], [28,28])    # 28x28\n",
    "    axes[0, t].imshow(test_disp_gt_crpt, cmap='gray')   \n",
    "    axes[0, t].set(ylabel='gt_crpt')\n",
    "    axes[0, t].label_outer()\n",
    "\n",
    "    test_disp_gen_pure = np.reshape(test_gen_pure[t], [28,28])    # 28x28\n",
    "    axes[1, t].imshow(test_disp_gen_pure, cmap='gray')   \n",
    "    axes[1, t].set(ylabel='gen_pure')\n",
    "    axes[1, t].label_outer()           \n",
    "\n",
    "    test_disp_gen_noise = np.reshape(test_gen_noise[t], [28,28])    # 28x28\n",
    "    axes[2, t].imshow(test_disp_gen_noise, cmap='gray')   \n",
    "    axes[2, t].set(ylabel='gen_noise')\n",
    "    axes[2, t].label_outer()\n",
    "\n",
    "    test_disp_gen_crpt = np.reshape(test_gen_crpt[t], [28,28])    # 28x28\n",
    "    axes[3, t].imshow(test_disp_gen_crpt, cmap='gray')   \n",
    "    axes[3, t].set(ylabel='gen_crpt')\n",
    "    axes[3, t].label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
